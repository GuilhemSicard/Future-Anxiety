{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e69f5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "import spacy\n",
    "from spacy.tokens import DocBin, Doc\n",
    "Doc.set_extension(\"ID\", default='')\n",
    "Doc.set_extension(\"headline\", default='')\n",
    "Doc.set_extension(\"label\", default='')\n",
    "import pandas as pd \n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "re.DEFAULT_VERSION = re.VERSION1\n",
    "import plotly.express as px\n",
    "from IPython.display import Image\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "import time\n",
    "import gc\n",
    "from bertopic import BERTopic \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f201c51",
   "metadata": {},
   "source": [
    "## Apply NLP pipeline for tokenization, lemmatization and other features for latter uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68eb89c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pageNum</th>\n",
       "      <th>paragraphNum</th>\n",
       "      <th>content</th>\n",
       "      <th>headline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Admbûstrateur . AUGUSTE DUNIONT ABOMMBHXins Pa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>m part ri pas demain à l'occasion du jour de l...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>20-21-22-23-24</td>\n",
       "      <td>Notre éclectisme en roli tique qui, pour être ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25-26</td>\n",
       "      <td>fœil bravement fixé sur le couteau, gravi les ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>27-28</td>\n",
       "      <td>. Hier matii , lés gens dé Batignolles considé...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791868</th>\n",
       "      <td>1910-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>Le sujet imaginé par MM. Gheusi et Mé rane aur...</td>\n",
       "      <td>LA SOIRÉE LE MIRACLE A L'OPÉRA</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791869</th>\n",
       "      <td>1910-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>9-10-11-12-13-14-15</td>\n",
       "      <td>M lle Chenal M. Muratore si l'on en juge parla...</td>\n",
       "      <td>A L'OPÉRA Le Miracle</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791870</th>\n",
       "      <td>1910-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>à 8 heures pour les représentations de M. Gili...</td>\n",
       "      <td>Ce-soir : A l'Opéra,</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791871</th>\n",
       "      <td>1910-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>18-19</td>\n",
       "      <td>l'Habitation forcée SUITE derrière le vert ble...</td>\n",
       "      <td>Feuilleton du FIGARO du 31 Décembre</td>\n",
       "      <td>autres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791872</th>\n",
       "      <td>1910-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>20-21-22-23-24</td>\n",
       "      <td>montrer le chien, le nez tout blanc de lait so...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>791873 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  pageNum         paragraphNum  \\\n",
       "0       1870-01-01        0                    9   \n",
       "1       1870-01-01        0                   13   \n",
       "2       1870-01-01        0       20-21-22-23-24   \n",
       "3       1870-01-01        0                25-26   \n",
       "4       1870-01-01        0                27-28   \n",
       "...            ...      ...                  ...   \n",
       "791868  1910-12-31        5                    7   \n",
       "791869  1910-12-31        5  9-10-11-12-13-14-15   \n",
       "791870  1910-12-31        5                   16   \n",
       "791871  1910-12-31        5                18-19   \n",
       "791872  1910-12-31        5       20-21-22-23-24   \n",
       "\n",
       "                                                  content  \\\n",
       "0       Admbûstrateur . AUGUSTE DUNIONT ABOMMBHXins Pa...   \n",
       "1       m part ri pas demain à l'occasion du jour de l...   \n",
       "2       Notre éclectisme en roli tique qui, pour être ...   \n",
       "3       fœil bravement fixé sur le couteau, gravi les ...   \n",
       "4       . Hier matii , lés gens dé Batignolles considé...   \n",
       "...                                                   ...   \n",
       "791868  Le sujet imaginé par MM. Gheusi et Mé rane aur...   \n",
       "791869  M lle Chenal M. Muratore si l'on en juge parla...   \n",
       "791870  à 8 heures pour les représentations de M. Gili...   \n",
       "791871  l'Habitation forcée SUITE derrière le vert ble...   \n",
       "791872  montrer le chien, le nez tout blanc de lait so...   \n",
       "\n",
       "                                   headline    label  \n",
       "0                                                     \n",
       "1                                 Le Figaro           \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     \n",
       "...                                     ...      ...  \n",
       "791868       LA SOIRÉE LE MIRACLE A L'OPÉRA  culture  \n",
       "791869                 A L'OPÉRA Le Miracle  culture  \n",
       "791870                 Ce-soir : A l'Opéra,  culture  \n",
       "791871  Feuilleton du FIGARO du 31 Décembre   autres  \n",
       "791872                                                \n",
       "\n",
       "[791873 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textDf = pd.read_csv('data/le_figaro.csv')\n",
    "textDf = textDf.fillna('')\n",
    "textDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b24343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████▎               | 391872/791873 [1:42:38<1:44:46, 63.63it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_bin = DocBin(store_user_data=True)\n",
    "\n",
    "nlp = spacy.load('fr_core_news_lg', exclude=[\"ner\"])\n",
    "texts = ((row.content, ('_'.join([str(row['date']),str(row['pageNum']),str(row['paragraphNum'])]), \n",
    "                        row['headline'], row['label']))\n",
    "         for _, row in textDf.iterrows())\n",
    "count = 0\n",
    "nDocs = len(textDf)\n",
    "with tqdm(total=len(textDf),mininterval = 5, miniters =1000) as pbar:\n",
    "    for doc, (ID, headline, label) in nlp.pipe(texts,as_tuples = True, batch_size=2048,n_process=16):\n",
    "        doc._.ID = ID\n",
    "        doc._.headline = headline\n",
    "        doc._.label = label\n",
    "        doc_bin.add(doc)\n",
    "        pbar.update(1)\n",
    "        #split data into several docbin\n",
    "        if (count%50_000 == 0) or (count == nDocs-1):\n",
    "            i = int(count/50_000)-4 if (count != nDocs-1) else int(count/50_000) -3\n",
    "            if count>0:\n",
    "                doc_bin.to_disk(f\"data/spacy/le_figaro{i}.spacy\")\n",
    "                del doc_bin\n",
    "                gc.collect()\n",
    "            doc_bin = DocBin(store_user_data=True)\n",
    "            \n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b92a652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488202d8",
   "metadata": {},
   "source": [
    "# Pachinko allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "191e37cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [02:14<00:00, 11.19s/it]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_lg', disable=[\"ner\"])\n",
    "\n",
    "doc_bin = DocBin(store_user_data=True)\n",
    "for root, dirs, files in os.walk('data/spacy'):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith((\".spacy\")):\n",
    "            doc_bin.merge(DocBin(store_user_data=True).from_disk(\"./data/spacy/\"+name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a336f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(doc):\n",
    "    ID = doc._.ID\n",
    "    headline = doc._.headline\n",
    "    label = doc._.label\n",
    "    oovRatio = np.mean([1 if word.is_oov else 0 for word in doc if word.is_alpha])\n",
    "    lemmas = [word.lemma_.lower() for word in doc \n",
    "           if word.is_alpha and (not word.is_stop) and (len(word.lemma_)>2) and (not word.is_oov)] \n",
    "    \n",
    "    return ID, doc.text, lemmas, oovRatio, headline, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d2a31b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709265\n"
     ]
    }
   ],
   "source": [
    "docs = [preprocess_text(doc) for doc in doc_bin.get_docs(nlp.vocab)]\n",
    "textDf = pd.DataFrame(docs, columns=['ID','content','lemmatized','oovRatio','headline','label'])\n",
    "textDf = textDf[(textDf.lemmatized.apply(len)>5) &\n",
    "                (textDf.oovRatio<0.6) &\n",
    "                (textDf.label=='')]\n",
    "print(len(textDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7d53f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_articles = textDf[\"lemmatized\"].tolist()\n",
    "bigram = Phrases(raw_articles, min_count=10, threshold=10)\n",
    "bigram_mod = Phraser(bigram)\n",
    "raw_articles = list(bigram_mod[raw_articles])\n",
    "trigram = Phrases(raw_articles, min_count=10, threshold=10)\n",
    "trigram_mod = Phraser(bigram)\n",
    "raw_articles = list(trigram_mod[raw_articles])\n",
    "textDf[\"nGram\"] = raw_articles\n",
    "textDf[\"nGram\"] = textDf[\"nGram\"].apply(' '.join)\n",
    "textDf[\"lemmatized\"] = textDf[\"lemmatized\"].apply(' '.join)\n",
    "textDf.to_csv('data/le_figaro_lemmatized_without_stop.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "textDf = pd.read_csv('data/le_figaro_lemmatized_without_stop.csv')\n",
    "raw_articles = textDf.nGram.str.split().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df3cf4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tp.utils.Corpus()\n",
    "for doc in raw_articles:\n",
    "    if doc:\n",
    "        corpus.add_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ac959",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1_max = 7\n",
    "k1_min = 2 \n",
    "k2_max = 18\n",
    "k2_min = 8\n",
    "params = []\n",
    "scores = []\n",
    "num_iter = 0\n",
    "max_iter = 0\n",
    "for k1 in range(k1_min, k1_max):\n",
    "    for k2 in range(max(k1,k2_min),k2_max):\n",
    "        max_iter +=1\n",
    "        \n",
    "start = time.time()\n",
    "for k1 in range(k1_min, k1_max):\n",
    "    for k2 in range(max(k1,k2_min),k2_max):\n",
    "        num_iter+=1\n",
    "        model = tp.PAModel(tw=tp.TermWeight.IDF,min_cf = 10, min_df=5, rm_top=25, k1=k1, k2=k2, corpus=corpus)\n",
    "        model.burn_in = 20\n",
    "        model.train(40, workers=24)\n",
    "        score = tp.coherence.Coherence(model, coherence=\"c_v\").get_score()\n",
    "        params.append((k1,k2))\n",
    "        scores.append(score)\n",
    "        print(\"Runtime: %.2f seconds\" %(time.time() - start), \"|| Number of Searches: %s out of  %s\" %(num_iter, max_iter), \"|| k1: %s & k2: %s || coherence : %.3f\" %(k1,k2,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "547d9af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1: 3 & k2: 9 || coherence : 0.659\n",
      "k1: 4 & k2: 11 || coherence : 0.685\n",
      "k1: 4 & k2: 14 || coherence : 0.694\n",
      "k1: 5 & k2: 15 || coherence : 0.668\n"
     ]
    }
   ],
   "source": [
    "for ind,score in enumerate(scores):\n",
    "    if score>max(scores)*0.95:\n",
    "        print(\"k1: %s & k2: %s || coherence : %.3f\" %(params[ind][0],params[ind][1],score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c9db869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7261144071817398\n"
     ]
    }
   ],
   "source": [
    "k1 = 4\n",
    "k2 = 14\n",
    "model = tp.PAModel(tw=tp.TermWeight.IDF,min_cf = 10, min_df=5, rm_top=25, k1=k1, k2=k2, corpus=corpus)\n",
    "model.burn_in = 20\n",
    "model.train(100, workers=24)\n",
    "score = tp.coherence.Coherence(model, coherence=\"c_v\").get_score()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fd6fbdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0\n",
      "\t ['gouvernement', 'angleterre', 'anglais', 'allemagne', 'ministre', 'russie', 'france', 'français', 'allemand', 'empereur']\n",
      "Topic #1\n",
      "\t ['officier', 'armée', 'troupe', 'soldat', 'capitaine', 'militaire', 'navire', 'commandant', 'guerre', 'colonel']\n",
      "Topic #2\n",
      "\t ['comte', 'mlle', 'comtesse', 'comte_comtesse', 'marquis', 'baron', 'vicomte', 'baronne', 'paul', 'docteur']\n",
      "Topic #3\n",
      "\t ['politique', 'france', 'pays', 'république', 'peuple', 'chose', 'esprit', 'gouvernement', 'estper', 'idée']\n",
      "Topic #4\n",
      "\t ['monsieur', 'femme', 'aller', 'oeil', 'dire', 'rien', 'main', 'cœur', 'vie', 'jamais']\n",
      "Topic #5\n",
      "\t ['rue', 'maison', 'eau', 'vendre', 'prix', 'franc', 'blanc', 'vin', 'noir', 'gramme']\n",
      "Topic #6\n",
      "\t ['prix', 'roi', 'course', 'fête', 'prince', 'cheval', 'palais', 'voiture', 'empereur', 'majesté']\n",
      "Topic #7\n",
      "\t ['théâtre', 'représentation', 'pièce', 'artiste', 'opéra', 'jouer', 'mlle', 'soir', 'succès', 'rôle']\n",
      "Topic #8\n",
      "\t ['franc', 'chambre', 'commission', 'député', 'loi', 'séance', 'million', 'budget', 'voter', 'projet']\n",
      "Topic #9\n",
      "\t ['rue', 'arrêter', 'femme', 'hier', 'âgé', 'police', 'agent', 'individu', 'maison', 'ouvrier']\n",
      "Topic #10\n",
      "\t ['gouvernement', 'président', 'loi', 'chambre', 'journal', 'contre', 'lettre', 'ministre', 'affaire', 'droit']\n",
      "Topic #11\n",
      "\t ['président', 'église', 'abbé', 'société', 'lieu', 'mgr', 'maire', 'évêque', 'docteur', 'nommer']\n",
      "Topic #12\n",
      "\t ['art', 'œuvre', 'livre', 'artiste', 'tableau', 'portrait', 'exposition', 'peintre', 'roman', 'volume']\n",
      "Topic #13\n",
      "\t ['monsieur', 'femme', 'dire', 'enfant', 'aller', 'père', 'bon', 'rien', 'mari', 'ami']\n"
     ]
    }
   ],
   "source": [
    "for k in range(k2):\n",
    "    print('Topic #{}'.format(k))\n",
    "    print(\"\\t\", [w for w, p in model.get_topic_words(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3532a",
   "metadata": {},
   "source": [
    "# BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "04068676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## tokenizer ici meme, découper pour doc entre 256 et 512 bert token, en respectant les phrases et fournir embeddings + token + text\n",
    "def splitLongDoc(doc):\n",
    "    if len(doc._.label) != 0:\n",
    "        return '','', ''\n",
    "    length = len(doc)\n",
    "    if length>=800:\n",
    "        nSegment = int(length/800)+1\n",
    "        maxLen = length/nSegment\n",
    "        content = ['']\n",
    "        for sentence in doc.sents:\n",
    "            sentLen = len(sentence)\n",
    "            if (len(content[-1])+sentLen<maxLen) or (len(content[-1]) < 200):\n",
    "                content[-1] = content[-1] +' '+ sentence.text\n",
    "            else:\n",
    "                content.append(sentence.text)\n",
    "        if len(content[-1])<100:\n",
    "            content[-2] = content[-2] + ' ' +content[-1]\n",
    "            content = content[:-1]\n",
    "            \n",
    "    else:\n",
    "        text = doc.text\n",
    "        content = [text] if len(text)>100 else ''\n",
    "        \n",
    "    return doc._.ID, content, doc._.headline\n",
    "            \n",
    "docs = [splitLongDoc(doc) for doc in doc_bin.get_docs(nlp.vocab)]\n",
    "docs = [(ID, content, headline) for ID, content, headline in docs if content != '']\n",
    "BERTDf = pd.DataFrame(docs, columns=['ID','content','headline'])\n",
    "BERTDf= BERTDf.explode('content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f23a71e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/gsicard/.cache/torch/sentence_transformers/dbmdz_bert-base-french-europeana-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/gsicard/.cache/torch/sentence_transformers/dbmdz_bert-base-french-europeana-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('dbmdz/bert-base-french-europeana-cased',device='cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ed038ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e30525e9a95487887310104b9e99aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/53489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_428161/2525552065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                        \u001b[0mmin_topic_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        vectorizer_model = vectorizer_model)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, documents, embeddings, y)\u001b[0m\n\u001b[1;32m    337\u001b[0m             self.embedding_model = select_backend(self.embedding_model,\n\u001b[1;32m    338\u001b[0m                                                   language=self.language)\n\u001b[0;32m--> 339\u001b[0;31m             embeddings = self._extract_embeddings(documents.Document,\n\u001b[0m\u001b[1;32m    340\u001b[0m                                                   \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                                   verbose=self.verbose)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m_extract_embeddings\u001b[0;34m(self, documents, method, verbose)\u001b[0m\n\u001b[1;32m   2785\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"document\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             raise ValueError(\"Wrong method for extracting document/word embeddings. \"\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bertopic/backend/_base.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, document, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mthat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0msize\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mm\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \"\"\"\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, documents, verbose)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mthat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0msize\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mm\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \"\"\"\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0;31m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mall_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "texts = BERTDf.content.tolist()\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 3), \n",
    "                                   max_df = 0.6,\n",
    "                                   min_df = 5,\n",
    "                                   strip_accents = 'unicode')\n",
    "topic_model = BERTopic(verbose=True,\n",
    "                       embedding_model=embedding_model,#'dbmdz/bert-base-french-europeana-cased',\n",
    "                       nr_topics = 'auto',\n",
    "                       min_topic_size = 100,\n",
    "                       vectorizer_model = vectorizer_model)\n",
    "topics, probs = topic_model.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2c7cca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2eb523dff4431f99619132d5c8780a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.4239223 ,  0.02248213, -0.20564407, ..., -0.8670402 ,\n",
       "        -0.22687754, -0.03607981],\n",
       "       [-0.24473065, -0.05312259, -0.09280771, ..., -0.5015501 ,\n",
       "         0.09548544,  0.5582943 ],\n",
       "       [-0.5172163 , -0.2801716 , -0.24598305, ..., -0.21981826,\n",
       "         0.14662059, -0.07403921],\n",
       "       ...,\n",
       "       [-0.33199543, -0.01667139, -0.2851535 , ..., -0.7983566 ,\n",
       "        -0.14050919,  0.04579991],\n",
       "       [-0.37848774,  0.03212813, -0.37159485, ..., -0.7773362 ,\n",
       "         0.20419456, -0.01591571],\n",
       "       [-0.46303445,  0.16347334, -0.29598263, ..., -0.7773549 ,\n",
       "        -0.1193127 ,  0.17085151]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.encode(texts[:2000],show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "a = tokenizer(texts[:20])\n",
    "print(time.time()-t)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e1ba05f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-french-europeana-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines import pipeline, autoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/electra-base-french-europeana-cased-discriminator\")\n",
    "model =  pipeline(\"feature-extraction\", model='dbmdz/bert-base-french-europeana-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "79956390",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model(texts[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a2cc1aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(texts[0])['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5d9d9931",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_428161/2438405782.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3343\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3345\u001b[0;31m         return self._decode(\n\u001b[0m\u001b[1;32m   3346\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "np.array(b) == np.array(model(tokenizer.decode(tokenizer(texts[:1])['input_ids'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bc33e23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>content</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1898-03-22_0_34</td>\n",
       "      <td>Mais, monsieur, il y a plus fort que cela en F...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1898-03-22_1_9</td>\n",
       "      <td>ble, que lesJAnglais occupent la baie de Mirs,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1898-03-22_2_24</td>\n",
       "      <td>CENTRAL-HOTEL, le plus grand et le plus élégan...</td>\n",
       "      <td>AVIS DIVERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1898-03-22_2_25</td>\n",
       "      <td>Demandez dans les bons restaurants l'exquis PE...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1898-03-23_2_30</td>\n",
       "      <td>Consultez votre médecin sur l'usage du Képhir ...</td>\n",
       "      <td>VOUS QUI SOUFFREZ DE L'ESTOMAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791821</th>\n",
       "      <td>1878-05-12_2_162</td>\n",
       "      <td>ENFANTS naturels. Constitution secrète d'ass '...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791823</th>\n",
       "      <td>1878-05-12_2_164</td>\n",
       "      <td>Ns hautes référ dem régie d'une g J propriété ...</td>\n",
       "      <td>INGÉ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791828</th>\n",
       "      <td>1878-05-12_2_230</td>\n",
       "      <td>FONDS ETRANGERS 3 0 0 CONSOLIDÉS, Midi heure é...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791846</th>\n",
       "      <td>1878-05-13_0_29</td>\n",
       "      <td>Deux médecins sont invités et présentés l'un à...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791868</th>\n",
       "      <td>1878-05-13_2_21</td>\n",
       "      <td>CH. OTJDIN, H ouloger. Fournisseur de la Marin...</td>\n",
       "      <td>NOTABILITES C08BKBO.4LIS RECOMMANDEES Horloger...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51892 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID                                            content  \\\n",
       "63       1898-03-22_0_34  Mais, monsieur, il y a plus fort que cela en F...   \n",
       "73        1898-03-22_1_9  ble, que lesJAnglais occupent la baie de Mirs,...   \n",
       "90       1898-03-22_2_24  CENTRAL-HOTEL, le plus grand et le plus élégan...   \n",
       "91       1898-03-22_2_25  Demandez dans les bons restaurants l'exquis PE...   \n",
       "169      1898-03-23_2_30  Consultez votre médecin sur l'usage du Képhir ...   \n",
       "...                  ...                                                ...   \n",
       "791821  1878-05-12_2_162  ENFANTS naturels. Constitution secrète d'ass '...   \n",
       "791823  1878-05-12_2_164  Ns hautes référ dem régie d'une g J propriété ...   \n",
       "791828  1878-05-12_2_230  FONDS ETRANGERS 3 0 0 CONSOLIDÉS, Midi heure é...   \n",
       "791846   1878-05-13_0_29  Deux médecins sont invités et présentés l'un à...   \n",
       "791868   1878-05-13_2_21  CH. OTJDIN, H ouloger. Fournisseur de la Marin...   \n",
       "\n",
       "                                                 headline  \n",
       "63                                                         \n",
       "73                                                         \n",
       "90                                            AVIS DIVERS  \n",
       "91                                                         \n",
       "169                        VOUS QUI SOUFFREZ DE L'ESTOMAC  \n",
       "...                                                   ...  \n",
       "791821                                                     \n",
       "791823                                               INGÉ  \n",
       "791828                                                     \n",
       "791846                                                     \n",
       "791868  NOTABILITES C08BKBO.4LIS RECOMMANDEES Horloger...  \n",
       "\n",
       "[51892 rows x 3 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "BERTDf[(BERTDf.content.apply(len)<120) & (BERTDf.content.apply(len)>75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39d5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
